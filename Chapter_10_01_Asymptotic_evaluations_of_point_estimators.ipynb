{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Asymptotic evaluations of point estimators\n",
    "\n",
    "## Asymptotics\n",
    "\n",
    "- $n$ = sample size\n",
    "- What happens when $n\\to\\infty$\n",
    "- Why do we care\n",
    "    - Often calculations simplify so we can find approximate inference procedures for large sample sizes\n",
    "    - Useful evaluation/comparison tools"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Consistency\n",
    "\n",
    "**Definition: Consistency**\n",
    "\n",
    "A sequence of estimators $W_n=W_n(X_1,X_2,...,X_n)$ is a consistent sequence of estimators of the parameter $\\theta$ if for every $\\epsilon > 0$ and every $\\theta\\in\\Theta$\n",
    "\n",
    "$\\lim_{n\\to\\infty}P(|W_n-\\theta|<\\epsilon)=1$\n",
    "\n",
    "We also say that $W_n$ is a consistent estimator\n",
    "\n",
    "- That is, $W_n\\overset{p}{\\to}\\theta$ for all $\\theta$, converages in probability.\n",
    "- A consistent estimator will be arbitrarily close to the parameter with high probability as sample size increases."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Example:\n",
    "\n",
    "- Let $X_1,X_2,...,X_n$ be iid. $N(\\theta,1)$. Show that $\\bar{X}_n$ is a consistent sequence of estimators for $\\theta$.\n",
    "\n",
    "    **Proof:** $\\lim_{n\\to\\infty}P(|\\bar{X}_n-\\theta|<\\epsilon)=1$\n",
    "\n",
    "    $\\begin{aligned}\n",
    "    P(|\\bar{X}_n-\\theta|<\\epsilon)\n",
    "    &=P(-\\epsilon<\\bar{X}_n-\\theta<\\epsilon)\\\\\n",
    "    &=P(-\\sqrt{n}\\epsilon<\\sqrt{n}(\\bar{X}_n-\\theta)<\\sqrt{n}\\epsilon)\\quad(CLT)\\\\\n",
    "    &=\\Phi(\\sqrt{n}\\epsilon)-\\Phi(-\\sqrt{n}\\epsilon)\\quad(\\Phi\\text{ is cdf of }N(0,1))\\\\\n",
    "    \\end{aligned}$\n",
    "\n",
    "    $\\lim_{n\\to\\infty}P(|\\bar{X}_n-\\theta|<\\epsilon)=\\lim_{n\\to\\infty}\\Phi(\\sqrt{n}\\epsilon)-\\lim_{n\\to\\infty}\\Phi(-\\sqrt{n}\\epsilon)=1-0=1$\n",
    "\n",
    "    **Or:** By WLLN, $\\bar{X}_n\\overset{p}{\\to}\\theta$ as $n\\to\\infty$\n",
    "\n",
    "    Note: the sample mean is always a consistent estimator of the population mean (by WLLN)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Consistent estimators\n",
    "\n",
    "**Theorem**\n",
    "\n",
    "If $W_n$ is a sequence of estimators of a parameter $\\theta$ satisfying\n",
    "1. $\\lim_{n\\to\\infty}Var(W_n)=0$\n",
    "2. $\\lim_{n\\to\\infty}bias(W_n)=0$\n",
    "\n",
    "then $W_n$ is a consistent sequence of estimators of $\\theta$\n",
    "\n",
    "**Proof:** by Chebychev\n",
    "\n",
    "$P(g(X)\\geq r)\\leq\\frac{E(g(X))}{r}$, where $g(X)$ is a non-negative function, $r>0$.\n",
    "\n",
    "Setting $g(X)=(X-\\theta)^2$, thus $P(|X-\\theta|\\geq \\epsilon)\\leq\\frac{E((X-\\theta)^2)}{\\epsilon^2}$.\n",
    "\n",
    "$E((X-\\theta)^2)=MSE(W_n)=Var(W_n)+bias(W_n)^2\\to 0$ as $n\\to\\infty$\n",
    "\n",
    "Therefore, $\\lim_{n\\to\\infty}P(|W_n-\\theta|\\geq\\epsilon)=0$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Consistency of sample mean\n",
    "- When $X_1,X_2,...,X_n$ are iid. $N(\\mu,\\sigma^2)$ then\n",
    "\n",
    "    $Var(\\bar{X}_n)=\\frac{\\sigma^2}{n}\\to 0$ as $n\\to\\infty$\n",
    "\n",
    "    $bias(\\bar{X}_n)=0$ as $n\\to\\infty$\n",
    "\n",
    "    so $\\bar{X}$ is a consistent estimator of $\\mu$\n",
    "- In fact, by WLLN for any random sample with a finite variance we have\n",
    "\n",
    "    $\\bar{X}_n\\overset{p}{\\to}E(X)$ as $n\\to\\infty$\n",
    "\n",
    "    Therefore, $\\bar{X}_n$ is a consistent estimator of $E(X)$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Example\n",
    "- Let $X_1,X_2,...,X_n$ be a random sample from $Uniform(0,\\theta),\\theta>0$\n",
    "- We found before (Lecture 4) that the MLE for $\\theta$ is $X_{(n)}$. Is $X_{(n)}$ a consistent estimator of $\\theta$?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## MLEs are (generally) consistent\n",
    "\n",
    "**Theorem**\n",
    "\n",
    "Let $X_1,X_2,...,X_n$ be a random sample from $f(x|\\theta)$ and let $\\hat{\\theta}$ be the MLE of $\\theta$. Under some regularity assumptions on $f(x|\\theta)$\n",
    "- $\\hat{\\theta}$ is a consistent estimator of $\\theta$\n",
    "- $\\tau(\\hat{\\theta})$ is a consistent estimator of $\\tau(\\theta)$, if $\\tau$ is a continuous function\n",
    "- One of the conditions: The support of the distribution cannot depend on $\\theta$\n",
    "    - E.g. Distribution that does not meet the conditions: $U(0,\\theta)$ from $Open AI$."
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
