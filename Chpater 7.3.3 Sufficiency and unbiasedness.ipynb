{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Sufficiency and Unbiasedness"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Rao-Blackwell Theorem\n",
    "- Rao-Blackwell Theorem is based on iterative expectation:\n",
    "\n",
    "    $E(X)=E(E(X|Y))$\n",
    "\n",
    "    $Var(X)=Var(E(X|Y))+E(Var(X|Y))$\n",
    "\n",
    "    - $E(X|Y)$ is a function of $Y$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Rao-Blackwell Theorem:**\n",
    "\n",
    "Let $W$ be any unbiased estimator of $\\tau(\\theta)$.\n",
    "\n",
    "let $T$ be a sufficient statistic for $\\theta$. \n",
    "\n",
    "Let $\\phi(T)=E(W|T)$.\n",
    "\n",
    "Then $E(\\phi(T))=\\tau(\\theta)$ and $Var(\\phi(T))\\leq Var(W)$ for all $\\theta$, \n",
    "\n",
    "that is , $\\phi(T)$ is a uniformaly better unbiased estimator of $\\tau(\\theta)$."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Note: Rao-Blackwell 只能找到一个相比于$W$更好（更小的方差）的无偏估计器 $\\phi(T)=E(W|T)$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Proof:**\n",
    "\n",
    "$E(W)=\\tau(\\theta)$\n",
    "\n",
    "$E(\\phi(T))=E(E(W|T))=E(W)=\\tau(\\theta)$\n",
    "\n",
    "$\\phi(T)$ is a also unbiased estimator of $\\tau(\\theta)$\n",
    "\n",
    "$Var(\\phi(T))=Var(E(W|T))=Var(W)-E(Var(X|Y))$\n",
    "\n",
    "- $Var(X|Y)\\geq 0\\Rightarrow E(Var(X|Y))\\geq 0$\n",
    "    - $Var(\\phi(T))\\leq Var(W)$ for all $\\theta$\n",
    "\n",
    "$T$ is sufficient statistic, so $f(\\mathbf{X}|T)$ does not depend on $\\theta$."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Furthermore**, $T$ is a sufficient statistic, so $f(\\mathbf{X}|T)$ does not depend on $\\theta$.\n",
    "\n",
    "$W$ is a function of $\\mathbf{X}$, so $f(W|T)$ does not depend on $\\theta$ either.\n",
    "\n",
    "Thus, $E(W|T)$ does not depend on $\\theta$.\n",
    "\n",
    "Therefore, $\\phi(T)$ is a sufficient statistic, since $\\phi(T)=E(W|T)$ is a fuction of $T$. \n",
    "\n",
    "And we can always find a better estimator by conditioning on a sufficient statistic."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Sufficiency and unbiased estimators\n",
    "\n",
    "- The Rao-Blackwell Theorem means that in our search for best unbiased estimators we only need to consider functions of sufficient statistics!\n",
    "    - Narrows the search!\n",
    "\n",
    "**Theorem 7.3.18**\n",
    "\n",
    "If $\\phi(T)$ is a best unbiased estimator of $\\tau(\\theta)$, then $\\phi(T)$ is unique.\n",
    "- Any other unbias estimator will have a larger variance than it.\n",
    "\n",
    "**Theorem 7.3.20**\n",
    "\n",
    "If $E(\\phi(T))=\\tau(\\theta)$, then $\\phi(T)$ is a best unbiased estimators of $\\tau(\\theta)$, *if and only if* $\\phi(T)$ is uncorrelated with all unbiased estimators of 0.\n",
    "- *if and only if* $T$ is complete sufficient statistic.\n",
    "\n",
    "**Theorem 7.3.23 - Lehmann-Scheffé (LS)**\n",
    "\n",
    "Let **$T$ be a complete sufficient statistic for a parameter $\\theta$**, and let $\\phi(T)$ be any estimator based only on $T$.\n",
    "\n",
    "Then $\\phi(T)$ is the unique best unbiased estimator of its expected value $\\big(E(\\phi(T))=\\tau(\\theta)\\big)$."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Note：完备话 $T$ 之后的 $\\phi(T)=E(W|T)$，才是 $\\tau(\\theta)$ 的 $UMVUE$。 "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Using Rao-Blackwell + LS to find UMVUE\n",
    "\n",
    "Say:\n",
    "- want to find a UMVUE if $\\tau(\\theta)$\n",
    "- have a complete sufficient statistic $T$\n",
    "\n",
    "If $E(T)=\\tau(\\theta)$, then by LS, $T$ is the UMVUE of $\\tau(\\theta)$.\n",
    "\n",
    "If $E(T)\\neq\\tau(\\theta)$, then\n",
    "1. Sometimes there is a obvious transformation $\\phi(T)$ that gives $E(\\phi(T))=\\tau(\\theta)$.\n",
    "2. If not, we can use $RB$ to find $\\phi(T)$, using some simple unbiased estimator $W$, then $\\phi(T)=E(W|T)$.\n",
    "\n",
    "by LS, $\\phi(T)$ is the UMVUE of $\\tau(\\theta)$."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Example:\n",
    "- Say $X_1,X_2,...,X_n$ are iid. $Poisson(\\theta)$. Show that $\\bar{X}$ is the best unbiased estimator of $\\theta$.\n",
    "\n",
    "    Saw before: $T=\\sum_{i=1}^n X_i$ is a complete sufficient statistic of $\\theta$.\n",
    "\n",
    "    $E(T)=\\sum_{i=1}^n E(X_i)=n\\theta\\neq\\theta$\n",
    "\n",
    "    but $E(\\frac{T}{n})=E(\\bar{X})=\\theta$\n",
    "\n",
    "    $\\bar{X}$ is a function of a complete statistic, because it is only based on $T$.\n",
    "\n",
    "    Therefore, $\\bar{X}$ is the $UMVUE$ of $\\theta$, by LS."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Example:\n",
    "- Say $X_1,X_2,...,X_n$ are iid. $Poisson(\\theta)$. Find the $UMVUE$ of\n",
    "\n",
    "    $\\begin{aligned}\n",
    "    P(X_i \\leq 1) \n",
    "    &= P(X_i = 0) + P(X_i = 1) \\\\\n",
    "    &= \\frac{e^{-\\theta} \\theta^0}{0!} + \\frac{e^{-\\theta} \\theta^1}{1!} \\\\\n",
    "    &= e^{-\\theta} + \\theta e^{-\\theta} = (1 + \\theta)e^{-\\theta} = \\tau(\\theta) \\\\\n",
    "    \\end{aligned}$\n",
    "\n",
    "    It is easy to know $T=\\sum_{i=1}^n X_i$ is complete sufficient statistic of $\\theta$.\n",
    "\n",
    "    Obviously, it is hard to find a $\\phi(T)$ as a UMVUE of $\\tau(\\theta)$, so let's use Rao-Blackwell.\n",
    "\n",
    "    Consider: \n",
    "    \n",
    "    $W(\\mathbf{X})=\n",
    "    \\begin{cases}\n",
    "    1 &X_1\\leq 1\\\\\n",
    "    0 &Otherwise\n",
    "    \\end{cases}$\n",
    "\n",
    "    $W\\sim Bernoulli(p)$, where $p=P(W=1)=P(X_1 \\leq 1)=(1 + \\theta)e^{-\\theta}$\n",
    "\n",
    "    $E(W)=p=(1 + \\theta)e^{-\\theta}$, so it is a unbiased estimator of $\\tau(\\theta)$.\n",
    "\n",
    "    According to the Rao-Blackwell,\n",
    "\n",
    "    $\\begin{aligned}\n",
    "    \\phi(T)\n",
    "    &=E(W|T)\\\\\n",
    "    &=\\sum_w w\\cdot P(W=w|T=t)\\\\\n",
    "    &=0\\cdot P(W=0|T=t)+1\\cdot P(W=1|T=t)\\\\\n",
    "    &=P(W=1|T=t)\\\\\n",
    "    &=P(X_1\\leq 1|\\sum_{i=1}^n X_i=t)\\\\\n",
    "    &=\\frac{P(X_1\\leq 1,\\sum_{i=1}^n X_i=t)}{P(\\sum_{i=1}^n X_i=t)}\\\\\n",
    "    &=\\frac{P(X_1= 0)\\cdot P(\\sum_{i=2}^n X_i=t) + P(X_1= 1)\\cdot P(\\sum_{i=2}^n X_i=t-1)}{P(\\sum_{i=1}^n X_i=t)}\\\\\n",
    "    \\end{aligned}$\n",
    "\n",
    "    $T\\sim Poisson(n\\theta)\\Rightarrow P(T=t)=\\frac{e^{-n\\theta}(n\\theta)^t}{t!}$\n",
    "\n",
    "    $\\sum_{i=2}^n X_i=t\\sim Poisson((n-1)\\theta)\\Rightarrow P(\\sum_{i=2}^n X_i=t)=\\frac{e^{-(n-1)\\theta}((n-1)\\theta)^t}{t!}$\n",
    "\n",
    "    $\\sum_{i=2}^n X_i=t-1\\sim Poisson((n-1)\\theta)\\Rightarrow P(\\sum_{i=2}^n X_i=t-1)=\\frac{e^{-(n-1)\\theta}((n-1)\\theta)^{(t-1)}}{(t-1)!}$\n",
    "\n",
    "    $\\begin{aligned}\n",
    "    \\phi(T)\n",
    "    &=\\frac{\\frac{e^{-\\theta} \\theta^0}{0!}\\cdot\\frac{e^{-(n-1)\\theta}((n-1)\\theta)^t}{t!}+\\frac{e^{-\\theta} \\theta^1}{1!}\\cdot\\frac{e^{-(n-1)\\theta}((n-1)\\theta)^{(t-1)}}{(t-1)!}}{\\frac{e^{-n\\theta}(n\\theta)^t}{t!}}\\\\\n",
    "    &=\\frac{(n-1)^{n\\bar{x}-1}(n\\bar{x}+n-1)}{n^{n\\bar{x}}}\n",
    "    \\end{aligned}$\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Best unbiased estimators - Summary\n",
    "\n",
    "- Let $W$ be an unbiased estimator of a parameter $\\theta$\n",
    "- Then $MSE(W)=Var(W)$\n",
    "- In general, we want our unbiased estimators to have low variance (and hence low MSE)\n",
    "\n",
    "    **Best unbiased estimator = Uniform minimum variance unbiased estimator (UMVUE)**\n",
    "- The estimator that has the smallest variance in the set of all unbiased estimators\n",
    "- Section 7.3 is mostly about different theoretical tricks to see if we have a best unbiased estimator"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Trick 1: Cramer-Rao Lower bound\n",
    "\n",
    "- Puts a lower bound on the variance of all estimators - given that some \"nicety\" conditions hold\n",
    "\n",
    "- Our estimators can’t have a smaller variance than the Cramer-Rao lower bound (CRLB)\n",
    "\n",
    "- So if our unbiased estimator has a variance that is equal to CRLB we know that it is the best unbiased estimator\n",
    "\n",
    "**Efficient estimators**\n",
    "\n",
    "An estimator W is called and efficient estimator if it has a variance that is equal to its CRLB\n",
    "- Note that a best unbiased estimator is not necessarily efficient\n",
    "- The CRLB may not be obtainable"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Trick 2: Complete statistic\n",
    "\n",
    "All we need is completeness:\n",
    "\n",
    "**Lehmann-Scheffé**\n",
    "\n",
    "Let $T$ be a complete sufficient statistic for a parameter $\\theta$, and let $\\phi(T)$ be any estimator based only on $T$. Then $\\phi(T)$ is the unique best unbiased estimator of its expected value.\n",
    "\n",
    "- Rao-Blackwell + Lehmann-Scheffé:\n",
    "    - Find a complete statistic $T$. If unbiased of $\\tau(\\theta)$, then we are done!\n",
    "    - If *not* unbiased, find a simple unbiased estimator $W$ and set\n",
    "\n",
    "        $\\phi(T)=E(W|T)$\n",
    "\n",
    "        then $\\phi(T)$ is unbiased and based only on a complete sufficient statistic $T$. Therefore $\\phi(T)$ is the best unbiased estimator of $\\tau(\\theta)$."
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
